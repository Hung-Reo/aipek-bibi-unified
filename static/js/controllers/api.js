// ‚úÖ UPDATED: Remove proxy, direct API calls
// Import RAG service (ƒë·∫£m b·∫£o api_rag.js ƒë∆∞·ª£c load tr∆∞·ªõc api.js)
// Th√™m ƒë·ªãnh nghƒ©a h√†m getBiBiResponse tr∆∞·ªõc khi export
async function getBiBiResponse(messages, options = {}) {
  try {
    // H·ª£p nh·∫•t options m·∫∑c ƒë·ªãnh v√† t√πy ch·ªçn ƒë∆∞·ª£c truy·ªÅn v√†o
    const apiOptions = {
      model: options.model || "gpt-4.1",
      temperature: options.temperature || 0.7,
      max_tokens: options.max_tokens || 2000,
      useRAG: options.useRAG !== false, // M·∫∑c ƒë·ªãnh s·ª≠ d·ª•ng RAG
      ...options
    };

    // √Åp d·ª•ng RAG n·∫øu ƒë∆∞·ª£c b·∫≠t v√† c√≥ ragService
    if (apiOptions.useRAG && window.ragService && messages.length > 0) {
      const lastUserMessage = messages.filter(m => m.role === 'user').pop();
      
      if (lastUserMessage) {
        try {
          console.log('üîÑ ƒêang t√¨m ki·∫øm th√¥ng tin RAG...');
          const ragResults = await window.ragService.search(lastUserMessage.content);
          
          if (ragResults.success && ragResults.results.length > 0) {
            console.log('‚úÖ ƒê√£ t√¨m th·∫•y th√¥ng tin RAG li√™n quan');
            // T·∫°o b·∫£n sao c·ªßa messages ƒë·ªÉ kh√¥ng ·∫£nh h∆∞·ªüng ƒë·∫øn m·∫£ng g·ªëc
            const enhancedMessages = [...messages];
            // T√¨m v√† c·∫≠p nh·∫≠t message cu·ªëi c√πng c·ªßa user
            for (let i = enhancedMessages.length - 1; i >= 0; i--) {
              if (enhancedMessages[i].role === 'user') {
                enhancedMessages[i] = {
                  ...enhancedMessages[i],
                  content: window.ragService.enhancePrompt(enhancedMessages[i].content, ragResults)
                };
                break;
              }
            }
            // S·ª≠ d·ª•ng enhancedMessages thay cho messages g·ªëc
            messages = enhancedMessages;
          } else {
            console.log('‚ÑπÔ∏è Kh√¥ng t√¨m th·∫•y th√¥ng tin RAG li√™n quan');
          }
        } catch (ragError) {
          console.warn('‚ö†Ô∏è L·ªói khi s·ª≠ d·ª•ng RAG, ti·∫øp t·ª•c kh√¥ng c√≥ RAG:', ragError);
        }
      }
    }
    
    console.log('üîÑ Streaming request to API with options:', {
      model: options.model,
      temperature: options.temperature,
      stream: true,
      messagesLength: messages.length
    });
    
    console.log('üîÑ Streaming request to API with options:', {
      model: options.model,
      temperature: options.temperature,
      stream: true,
      messagesLength: messages.length
    });
    console.time('API Call Duration');
    // ‚úÖ UPDATED: Direct API call to unified server
    const response = await fetch("/api/chat", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        messages: messages,
        ...apiOptions
      })
    });
    
    const data = await response.json();
    console.timeEnd('API Call Duration');
    
    if (data.error) {
      throw new Error(data.error.message || "API error");
    }
    
    return data.choices[0].message.content;
  } catch (error) {
    console.error("API Error:", error);
    throw new Error("Kh√¥ng th·ªÉ k·∫øt n·ªëi t·ªõi API: " + error.message);
  }
}

// Th√™m v√†o api.js c≈©
async function streamBiBiResponse(messages, updateCallback, options = {}) {
  try {
    const apiOptions = {
      model: options.model || "gpt-4.1",
      temperature: options.temperature || 0.7,
      max_tokens: options.max_tokens || 2000,
      stream: true,
      ...options
    };
    console.log('üöÄ API.js loaded successfully')
    console.log('Sending streaming request');
    // ‚úÖ UPDATED: Direct API call to unified server
    const response = await fetch("/api/chat", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        messages: messages,
        ...apiOptions
      })
    });
    
    if (!response.ok) {
      const errorData = await response.json();
      throw new Error(errorData.error?.message || `API Error: ${response.status}`);
    }

    // X·ª≠ l√Ω streaming response
    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    let fullText = '';
    
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      
      const text = decoder.decode(value, { stream: true });
      const lines = text.split('\n');
      
      for (const line of lines) {
        if (line.startsWith('data: ') && line !== 'data: [DONE]') {
          try {
            const data = JSON.parse(line.substring(6));
            const content = data.choices[0]?.delta?.content || '';
            if (content) {
              fullText += content;
              if (updateCallback) updateCallback(content, fullText);
            }
          } catch (e) {
            console.warn('Error parsing SSE data:', e);
          }
        }
      }
    }
    
    return fullText;
  } catch (error) {
    console.error("API Streaming Error:", error);
    throw new Error("Kh√¥ng th·ªÉ k·∫øt n·ªëi t·ªõi API streaming: " + error.message);
  }
}

// Th√™m ƒë·ªãnh nghƒ©a cho getSpeechToken ƒë·ªÉ tr√°nh l·ªói
async function getSpeechToken() {
  try {
    // ‚úÖ UPDATED: Direct API call to unified server
    const response = await fetch("/api/speech-token", {
      method: "POST",
      headers: { "Content-Type": "application/json" }
    });
    return await response.json();
  } catch (error) {
    console.error("Speech Token Error:", error);
    throw new Error("Kh√¥ng th·ªÉ l·∫•y token cho speech: " + error.message);
  }
}

// Xu·∫•t c√°c h√†m
window.getBiBiResponse = getBiBiResponse;
window.streamBiBiResponse = streamBiBiResponse;
window.getSpeechToken = getSpeechToken;